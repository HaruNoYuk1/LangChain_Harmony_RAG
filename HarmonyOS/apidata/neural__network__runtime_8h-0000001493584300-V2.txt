您正在浏览HarmonyOS开发者3.1/4.0版本配套的开发者文档，对应API能力级别为API 9 Release，详细版本配套关系请参考版本说明。概述汇总函数neural_network_runtime.h 更新时间: 2024-02-07 14:08 毫无帮助帮助不大一般很好非常好
分享
  概述Neural Network Runtime部件接口定义，AI推理框架通过Neural Network Runtime提供的Native接口，完成模型构造与编译，并在加速硬件上执行推理计算。 起始版本： 9 相关模块： NeuralNeworkRuntime  汇总 函数  函数名称 描述 OH_NNModel_Construct (void) 创建OH_NNModel类型的模型实例，搭配OH_NNModel模块提供的其他接口，完成模型实例的构造。  OH_NNModel_AddTensor (OH_NNModel *model, const OH_NN_Tensor *tensor) 向模型实例中添加张量。  OH_NNModel_SetTensorData (OH_NNModel *model, uint32_t index, const void *dataBuffer, size_t length) 设置张量的数值。  OH_NNModel_AddOperation (OH_NNModel *model, OH_NN_OperationType op, const OH_NN_UInt32Array *paramIndices, const OH_NN_UInt32Array *inputIndices, const OH_NN_UInt32Array *outputIndices) 向模型实例中添加算子。  OH_NNModel_SpecifyInputsAndOutputs (OH_NNModel *model, const OH_NN_UInt32Array *inputIndices, const OH_NN_UInt32Array *outputIndices) 指定模型的输入输出。  OH_NNModel_Finish (OH_NNModel *model) 完成模型构图。  OH_NNModel_Destroy (OH_NNModel **model) 释放模型实例。  OH_NNModel_GetAvailableOperations (OH_NNModel *model, size_t deviceID, const bool **isSupported, uint32_t *opCount) 查询硬件对模型内所有算子的支持情况，通过布尔值序列指示支持情况。  OH_NNCompilation_Construct (const OH_NNModel *model) 创建OH_NNCompilation类型的编译实例。  OH_NNCompilation_SetDevice (OH_NNCompilation *compilation, size_t deviceID) 指定模型编译和计算的硬件。  OH_NNCompilation_SetCache (OH_NNCompilation *compilation, const char *cachePath, uint32_t version) 设置编译后的模型缓存路径和缓存版本。  OH_NNCompilation_SetPerformanceMode (OH_NNCompilation *compilation, OH_NN_PerformanceMode performanceMode) 设置模型计算的性能模式。  OH_NNCompilation_SetPriority (OH_NNCompilation *compilation, OH_NN_Priority priority) 设置模型计算的优先级。  OH_NNCompilation_EnableFloat16 (OH_NNCompilation *compilation, bool enableFloat16) 是否以float16的浮点数精度计算。  OH_NNCompilation_Build (OH_NNCompilation *compilation) 进行模型编译。  OH_NNCompilation_Destroy (OH_NNCompilation **compilation) 释放Compilation对象。  OH_NNExecutor_Construct (OH_NNCompilation *compilation) 创建OH_NNExecutor类型的执行器实例。  OH_NNExecutor_SetInput (OH_NNExecutor *executor, uint32_t inputIndex, const OH_NN_Tensor *tensor, const void *dataBuffer, size_t length) 设置模型单个输入的数据。  OH_NNExecutor_SetOutput (OH_NNExecutor *executor, uint32_t outputIndex, void *dataBuffer, size_t length) 设置模型单个输出的缓冲区。  OH_NNExecutor_GetOutputShape (OH_NNExecutor *executor, uint32_t outputIndex, int32_t **shape, uint32_t *shapeLength) 获取输出张量的维度信息。  OH_NNExecutor_Run (OH_NNExecutor *executor) 执行推理。  OH_NNExecutor_AllocateInputMemory (OH_NNExecutor *executor, uint32_t inputIndex, size_t length) 在硬件上为单个输入申请共享内存。  OH_NNExecutor_AllocateOutputMemory (OH_NNExecutor *executor, uint32_t outputIndex, size_t length) 在硬件上为单个输出申请共享内存。  OH_NNExecutor_DestroyInputMemory (OH_NNExecutor *executor, uint32_t inputIndex, OH_NN_Memory **memory) 释放OH_NN_Memory实例指向的输入内存。  OH_NNExecutor_DestroyOutputMemory (OH_NNExecutor *executor, uint32_t outputIndex, OH_NN_Memory **memory) 释放OH_NN_Memory实例指向的输出内存。  OH_NNExecutor_SetInputWithMemory (OH_NNExecutor *executor, uint32_t inputIndex, const OH_NN_Tensor *tensor, const OH_NN_Memory *memory) 将OH_NN_Memory实例指向的硬件共享内存，指定为单个输入使用的共享内存。  OH_NNExecutor_SetOutputWithMemory (OH_NNExecutor *executor, uint32_t outputIndex, const OH_NN_Memory *memory) 将OH_NN_Memory实例指向的硬件共享内存，指定为单个输出使用的共享内存。  OH_NNExecutor_Destroy (OH_NNExecutor **executor) 销毁执行器实例，释放执行器占用的内存。  OH_NNDevice_GetAllDevicesID (const size_t **allDevicesID, uint32_t *deviceCount) 获取对接到 Neural Network Runtime 的硬件ID。  OH_NNDevice_GetName (size_t deviceID, const char **name) 获取指定硬件的类型信息。  OH_NNDevice_GetType (size_t deviceID, OH_NN_DeviceType *deviceType) 获取指定硬件的类别信息。      上一篇 neural_network_runtime_type.h 下一篇 native_avcodec_audiodecoder.h 以上内容对您是否有帮助？毫无帮助帮助不大一般很好非常好意见反馈
更多帮助请到“社区论坛”，如需要其他帮助，请通过“智能客服”提问。